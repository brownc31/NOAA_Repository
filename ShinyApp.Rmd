---
title: "App Development Teehee"
output: pdf_document
date: "2024-06-12"
---

```{r}
#load libraries for shiny app
library(tidyverse)
library(readr)
library(lubridate)
library(ggplot2)
library(readxl)
library(broom)
library(patchwork)
library(car)
library(shiny)
library(shinydashboard)
library(shinyWidgets)
library(raster)
library(sf)
library(leaflet)
```

```{r}
#load in data to app
set.seed(12030)
big_data <- read_csv("~/Desktop/NOAA/NOAA_Repository/Shiny Data/big_data.csv")
sf <- read_csv("~/Desktop/NOAA/NOAA_Repository/Shiny Data/sf.csv") %>% 
  rename(`Percent of Removable Titrations` = mean_percent_replaceable, `Depth of Lowest Oxygen Level` = low_oxy_depth, `Ocean Depth` = mean_max_depth,
         `Number of Removable Titrations` = number_replacements, `Historical Number of Titrations` = site_samples, 
         `Number of Stations` = number_of_stations, `Suggested Number of Titrations` = suggested_samples)
big_data3 <- read_csv("~/Desktop/NOAA/NOAA_Repository/Shiny Data/LMData.csv")
```

```{r}
#creates function for analysis with % threshold
replacements_pct <- function(calibration_data, raw_data, threshold) {
 
  replaceable <- 0
  
  
  for (i in 1:length(calibration_data)) {
    new_data <- calibration_data
    index <- sample(1:length(calibration_data), i)
    new_data[index] <- raw_data[index]
    
    if (mean(abs((new_data - calibration_data) / calibration_data)) <= threshold) {
      replaceable <- replaceable + 1
      
    }
    
  }
  
  return(replaceable)
}
```

```{r}
#creates function for analysis with umol/kg threshold
replacements_unit <- function(calibration_data, raw_data, threshold) {
 
  replaceable <- 0
  
  
  for (i in 1:length(calibration_data)) {
    new_data <- calibration_data
    index <- sample(1:length(calibration_data), i)
    new_data[index] <- raw_data[index]
    
    if (mean(abs(new_data - calibration_data)) <= threshold) {
      replaceable <- replaceable + 1
      
    }
    
  }
  
  return(replaceable)
}
```

--------------------------------------------------------------------------------

```{r}
#creating user interface
ui <- dashboardPage(
  dashboardHeader(title = h4(HTML("Optimizing Ocean Oxygen Sampling"))),
  
  #set up tab system
  dashboardSidebar(
    sidebarMenu(
      #creating tabs
      menuItem("Info", tabName = "Info", icon = icon("info-circle")),
      menuItem("Map", tabName = "Map", icon = icon("map-marked-alt")),
      menuItem("Profiles", tabName = "IntPlots", icon = icon("cog")),
      menuItem("Plots", tabName = "Plots", icon = icon("line-chart")),
      menuItem("Linear Modeling", tabName = "LM", icon = icon("globe-oceania"))
    )
  ),
  
  #set up contents of each tab
  dashboardBody(
    tabItems(
      tabItem(tabName = "Info",
              
              h2("Background"),
              
              p("NOAA leads annual ocean acidification research cruises in locations surrounding the USA. This analysis specifically focuses on the ECOA 2022, WCOA 2021, and GOMECC 2021 cruises which take place in the East Coast, West Coast, and Gulf of Mexico respectively. This omits cruises in the Alaska, Arctic, and Pacific Islands. On each cruise two types of oxygen samples are taken. \n 
                1. samples from the CTD oxygen sensor that provides data for a full oxygen profile, which is to say continuous data. \n 
                2. titration samples from the bottles attached to the CTD. These bottles collect water samples at various depths which are used for calculating the amount of dissolved oxygen via titration. \n
                Although more accurate, the titration data is time-costly and consumes resources compared to the sensor data which is much more efficient to collect. Therefore it is important that we only take as many titrations as necessary to recieve accurate enough data. This app provides the findings from this analysis in a clear and interpretable way in order for simple usage by cruise personnel."),
              
              h2("Data"),
              
              p("Data was obtained from ECOA 2022, WCOA 2021, and GOMECC 2021. Each cruise had a dataset containing the raw CTD sensor data and the calibrated CTD sensor data. The calibrated CTD sensor data is calculated through correcting the raw CTD sensor data based on the titration data. The data was filtered so that each row represented one bottle sample. Within each row, the depth, raw sensor data, calibrated sensor data, titration data, temperature, salinity, location, and depth of station were measured."),
              
              h2("Analysis"),
              
              p("The number of titrations that could be replaced was estimated through calculating how many raw CTD sensor data points in any given profile could be replaced with the calibrated data points before the profile deviated by 1% or more. Then a suggested number of titrations was calculated by subtracting that number from the historical sample size of any given station. These results are visualized in an interactive map seen in the Map tab. Other findings are shown in the plotiing tabs (interactive plots and plots)."),
              
              p("In order to change the threshold from 1% to another value in umol/kg or %, feel free to edit the boxes below. All of the maps and plots in the other tabs will change based on this value once the 'Update App' button is clicked."),
              
              #where user selects a threshold value
              box(numericInput("threshold",
                              "Select a Threshold Value",
                              min = 0, max = 100,
                              value = 1,
                              step = 0.1)),
              
              #where user selects a unit
              box(selectInput("unit", 
                              "Select a Unit Type", 
                              c("%", "umol/kg"))),

              ),
      
      tabItem(tabName = "Map",
              
              fluidRow(
                
                br(),
                
                box(width = 12, leafletOutput("map", height = 700),
                    
                    pickerInput("var", #user chooses variable to plot
                                "Select a Variable",
                                choices = names(sf)[c(3:9)],
                                selected = "Suggested Number of Samples"))),
                p("This map shows the average of different variables within each area. Each box is 2 decimal degrees longitude by 2 decimal degrees latitude. This area was decided upon as an area that could be both specific and contain enough data to reach better conclusions. The average suggested number of titrations is determined by the historical average sample size minus the average number of removable titrations for each area. The range was determined by the historical average sample size minus the max/min of the number of removable titrations for each area."),
                p("Both depth variables are measured in meters")
              ),
      
      tabItem(tabName = "IntPlots", 
              fluidRow(
                box(width = 12, plotOutput("Comparison"),
                    #where the user selects a cruise to view
                    pickerInput("Cruise", "Select a Cruise",
                                choices = unique(big_data$cruise),
                                selected = "WCOA 2021"),
                    uiOutput("station_max"), #references server for updated input choices
                    checkboxInput("cal", "Include Calibrated Sensor Data", value = FALSE)) #checkbox for the inclusion of calibrated data
                ),
              p("This interactive plot allows the user to look at specific profiles. Choose a cruise and a station in order to view that profile. Click the checkbox to include the calibrated oxygen sensor profile.")
              ),
      
      #tab for plots that don't require user interaction
      tabItem(tabName = "Plots",
              fluidRow(
                imageOutput("Coasts"),
                box(p("This plot shows how profiles differ based on their coastal location.")),
                br(),
                box(width = 12, plotOutput("distribution")),
                box(width = 12, p("This histogram shows the distribution of what percent of titrations can be removed from all profiles. This distribution is right skewed; generally it seems about 1/4 of titrations can be removed.")),
                br(),
                box(width = 12, plotOutput("boxplot")),
                box(width = 12, p("These boxplots show the distributions of removability based on coast. The main thing to note is that these boxplots have large spans, meaning there is a lot of variability in the amount of titrations that can be removed."))
              )),
      
      tabItem(tabName = "LM",
              fluidRow(
              box(h4("What if we want to decide how many samples to take based on depth?"),
              p("Plotting the number of historical samples taken based on the natural log of the depth of the site, we see that there are very linear relationships among the three coasts with high significance. Therefore, we can use a linear model to estimate the number of historically taken samples based on cruise and depth."),
              p("When we look the the same relationship but with the suggested number of titrations to be taken, we get similar results (with slightly less significance, and no significance for the difference between ECOA and GOMECC cruises). Therefore, we can also estimate the number of suggested titrations to take based on cruise and depth.")),
              box(pickerInput("Cruise2", "Select a Cruise",
                                choices = unique(big_data$cruise),
                                selected = "WCOA 2021"),
                  numericInput("Depth",
                              "Type a depth",
                              min = 0, max = 10000,
                              value = 500,
                              step = 0.1),
                  actionButton("update", "Update Answer")),
              box(h2("The historical number of samples would be: "),
                  textOutput("HistNum"),
                  h2("The Suggested Number of Samples is: "),
                  textOutput("SugNum"))
              ))
              ))
    )
  
  
```

```{r}
#creating server
server <- function(input, output, session) {
  
  # Updates input choices for station based on cruise
  output$station_max <- renderUI({
    stations <- big_data %>% 
      filter(cruise == input$Cruise) %>% 
      pull(Station)
    
    numericInput("station", "Select a Station",
                 min = 1, max = max(stations),
                 value = 108,
                 step = 1)
  })
  
  # Updates data set based on user inputs for threshold value and units
  data_reactive <- reactive({
    big_data2 <- big_data %>% 
      mutate(raw_oxy_change = raw_oxygen - lag(raw_oxygen, n = 1)) %>% 
      filter(raw_oxy_change != 0) %>% 
      dplyr::select(!raw_oxy_change) %>% 
      group_by(Station, cruise) %>% 
      mutate(replaceables = ifelse(input$unit == "%", replacements_pct(ctdoxy, raw_oxygen, input$threshold/100), replacements_unit(ctdoxy, raw_oxygen, input$threshold))) %>% 
      mutate(percent_replaceable = replaceables / n(), samples = n()) %>% 
      ungroup() %>% 
      arrange(desc(samples)) %>% 
      slice(-c(20:37)) %>% 
      arrange(cruise, Station) %>% 
      mutate(random_choices = runif(n()) < percent_replaceable) %>% 
      mutate(new_profile = ifelse(random_choices, raw_oxygen, ctdoxy))
  })
  
  # More data updating
  sf_data <- reactive({
    rounded_data <- data_reactive() %>% 
      mutate(latitude = 2* round(latitude / 2), longitude = 2 * round(longitude / 2), 
             station_change = ifelse(Station - lag(Station, n = 1) != 0, 1, 0)) %>% 
      group_by(latitude, longitude) %>% 
      summarize(`Percent of Removable Titrations` = mean(percent_replaceable), sample_size = n(), sd_replaceable = sd(percent_replaceable),
                `Depth of Lowest Oxygen Level` = median(median(ifelse(oxygen == min(oxygen), ctdprs, NA), na.rm = TRUE)), 
                low_oxy_depth_prop = median(`Depth of Lowest Oxygen Level` / max_depth), `Ocean Depth` = mean(max_depth),
                `Number of Removable Titrations` = mean(replaceables), sd_num = sd(replaceables), `Historical Number of Titrations` = mean(samples),
                lb = 100 * quantile(percent_replaceable, 0.05), num_lb = quantile(replaceables, 0.05), min_pct_replaceable = min(percent_replaceable), max_pct_replaceable = max(percent_replaceable),
                `Number of Stations` = sum(station_change))
    rounded_data$`Number of Stations`[73] <- 1

    # Define range of latitudes and longitudes
    lat_range <- seq(min(rounded_data$latitude), max(rounded_data$latitude), by = 2)
    lon_range <- seq(min(rounded_data$longitude), max(rounded_data$longitude), by = 2)

    # Initialize an empty list to store polygons
    polygons <- list()

    # Create polygons
    for (lat in lat_range) {
      for (lon in lon_range) {
        if(any(rounded_data$latitude == lat & rounded_data$longitude == lon)) {
          # Define the coordinates of the corners of the polygon
          coords <- matrix(c(lon - 1, lat - 1,
                             lon + 1, lat - 1,
                             lon + 1, lat + 1,
                             lon - 1, lat + 1,
                             lon - 1, lat - 1),
                           ncol = 2, byrow = TRUE)
          # Create a polygon and add it to the list
          polygons <- c(polygons, list(Polygons(list(Polygon(coords)), ID = paste(lat, lon))))
        }
      }
    }

    # Create a SpatialPolygons object
    sp_polygons <- SpatialPolygons(polygons)

    # Run code for formula without adjustments
    rounded_data <- rounded_data %>% 
      mutate(ID = paste(latitude, longitude), mean_pct_removable = 100 * `Percent of Removable Titrations`, sd = 100 * sd_replaceable, 
             `Suggested Number of Titrations` = ifelse((`Historical Number of Titrations` - ((`Percent of Removable Titrations`)*`Historical Number of Titrations`)) > 20, 20, `Historical Number of Titrations` - ((`Percent of Removable Titrations`)*`Historical Number of Titrations`)),
             `Suggested Number of Titrations` = ifelse((`Historical Number of Titrations` - ((`Percent of Removable Titrations`)*`Historical Number of Titrations`)) < 3, 3, `Historical Number of Titrations` - ((`Percent of Removable Titrations`)*`Historical Number of Titrations`)),
             min_suggested = ifelse(`Historical Number of Titrations` - (min_pct_replaceable*`Historical Number of Titrations`) < 5, 5, `Historical Number of Titrations` - (min_pct_replaceable*`Historical Number of Titrations`)), 
             max_suggested = ifelse(`Historical Number of Titrations` - (max_pct_replaceable*`Historical Number of Titrations`) < 3, 3, `Historical Number of Titrations` - (max_pct_replaceable*`Historical Number of Titrations`))) %>% 
      arrange(latitude, longitude) 

    rownames(rounded_data) <- rounded_data$ID

    spdf <- SpatialPolygonsDataFrame(sp_polygons, data = rounded_data)

    sf <- st_as_sf(spdf)
    return(sf) # Returns data set for mapping based on user input for threshold value and units
  })
  
  # Render leaflet map
  output$map <- renderLeaflet({
    
    if(as.character(input$var) == "Suggested Number of Titrations"){ # If the variable chosen is the number of suggested samples:
      palette <- colorNumeric(palette = "YlOrRd", domain = sf_data()[[input$var]])

      leaflet(sf_data()) %>% 
        addProviderTiles(providers$OpenStreetMap) %>% 
        addPolygons(color = ~palette(sf_data()[[input$var]]),
                    weight = 1,
                    opacity = 1,
                    fillOpacity = 0.7,
                    fillColor = ~palette(sf_data()[[input$var]]),
                    popup = ~paste("Avg: ", round(sf_data()[[input$var]], 0), "<br> Range: ", round(sf_data()$max_suggested, 0), " to ",  round(sf_data()$min_suggested, 0))) %>% # Then include its range
        addLegend(
          position = "bottomright",
          pal = palette,
          values = sf_data()[[input$var]],
          title = "Suggested Samples")
    } else { # If it is another variable:
      palette <- colorNumeric(palette = "YlOrRd", domain = sf_data()[[input$var]])

      leaflet(sf_data()) %>% 
        addProviderTiles(providers$OpenStreetMap) %>% 
        addPolygons(color = ~palette(sf_data()[[input$var]]),
                    weight = 1,
                    opacity = 1,
                    fillOpacity = 0.7,
                    fillColor = ~palette(sf_data()[[input$var]]),
                    popup = ~paste("Avg: ", round(sf_data()[[input$var]], 2))) %>% # Then only include the average
        addLegend(
          position = "bottomright",
          pal = palette,
          values = sf_data()[[input$var]],
          title = input$var)
    }
  })
  
  #outputs an image of a graph I made that has no reason to be updated
output$Coasts <- renderImage({
  list(src = "~/Desktop/NOAA/NOAA_Repository/Shiny Data/coasts.png")
  }, deleteFile = FALSE) 

#creates profile plots beased on user inputs for cruise, station, and whether to include calibration data or not
output$Comparison <- renderPlot({
 # if(station is in list of stations for cruise){
  if(input$cal == FALSE){
  data_reactive() %>% 
  filter(cruise == input$Cruise & Station == input$station) %>% 
  ggplot() +
  geom_point(aes(x = raw_oxygen, y = ctdprs), color  = "darkblue") +
  geom_line(aes(x = raw_oxygen, y = ctdprs), color  = "darkblue", orientation = "y") +
  geom_point(aes(x = oxygen, y = ctdprs), color = "red") +
  geom_line(aes(x = oxygen, y = ctdprs), color = "red", orientation = "y") +
  scale_y_reverse() + 
  labs(title = "Raw Sensor Profile (Blue) Vs Titration Profile (Red)", x = "Oxygen (umol/kg)", y = "Depth (m)", caption = str_glue("{input$Cruise}, {input$station}"))
  }
  else{
  data_reactive() %>% 
  filter(cruise == input$Cruise & Station == input$station) %>% 
  ggplot() +
  geom_point(aes(x = raw_oxygen, y = ctdprs), color  = "darkblue") +
  geom_line(aes(x = raw_oxygen, y = ctdprs), color  = "darkblue", orientation = "y") +
  geom_point(aes(x = oxygen, y = ctdprs), color = "red") +
  geom_line(aes(x = oxygen, y = ctdprs), color = "red", orientation = "y") +
  geom_point(aes(x = ctdoxy, y = ctdprs), color = "darkgreen") +
  geom_line(aes(x = ctdoxy, y = ctdprs), color = "darkgreen", orientation = "y") +
  scale_y_reverse() + 
  labs(title = "Raw Sensor Profile (Blue) Vs Titration Profile (Red) Vs Calibrated Sensor Profile (Green)", x = "Oxygen (umol/kg)", y = "Depth (m)", caption = str_glue("{input$Cruise}, {input$station}"))  
  }
  #else{
    #print(str_glue("{input$station} does not exist for this cruise"))
  #}
})

#creates boxplot that depends on threshold value/units
output$boxplot <- renderPlot({
ggplot(data = data_reactive(), aes(x = percent_replaceable, y = cruise)) +
  geom_boxplot() + 
  labs(title = "Percent Removable Samples by Cruise", x = "% Removable", y = "Cruise")
})

#creates histogram that depends on threshold value/units
output$distribution <- renderPlot({
ggplot(data = data_reactive(), aes(x = percent_replaceable)) +
  geom_histogram(binwidth = .05) +
  labs(title = "Distribution of the Removability of Profiles", y = "Number of Profiles", x = "% Removable")
})

HistNum <- reactive({
  req(input$update)
  if (input$Cruise2 == "ECOA 2022"){
  HistAns <- -1.7568 + (1.8217 * log(input$Depth))
  as.character(round(HistAns, 0))
  }
  
  else if (input$Cruise2 == "GOMECC 2021"){
  HistAns <- 0.0412 + (1.2901 * log(input$Depth))
  as.character(round(HistAns, 0))
  }
  
  else if (input$Cruise2 == "WCOA 2021"){
  HistAns <- -5.1696 + (3.2456 * log(input$Depth))
  }
  as.character(round(HistAns, 0))
})

output$HistNum <- renderText({
  HistNum()
})

lm_data <- reactive({
  big_data3 <- data_reactive() %>% 
  group_by(Station, cruise) %>% 
  summarize(suggested_samples = mean(samples - replaceables), max_depth = mean(max_depth), site_samples = mean(samples),
            percent_replaceable = mean(percent_replaceable), mean_removable = mean(replaceables))
})

  model <- reactive({
    lm(suggested_samples ~ log(max_depth) * cruise, data = lm_data())
  })

  # Reactive expression for the summary
  summary_model <- reactive({
    summary(model())
  })

  # Reactive expression for the coefficients
  coefficients <- reactive({
    summary_model()$coefficients
  })

  # Calculate the intercepts and slopes
  wcoa_intercept <- reactive({
    coefficients()["(Intercept)", "Estimate"]
  })

  wcoa_slope <- reactive({
    coefficients()["log(max_depth)", "Estimate"]
  })

  gomecc_intercept <- reactive({
    coefficients()["cruiseGOMECC 2021", "Estimate"]
  })

  gomecc_slope <- reactive({
    coefficients()["log(max_depth):cruiseGOMECC 2021", "Estimate"]
  })

  ecoa_intercept <- reactive({
    coefficients()["cruiseECOA 2022", "Estimate"]
  })

  ecoa_slope <- reactive({
    coefficients()["log(max_depth):cruiseECOA 2022 ", "Estimate"]
  })

  # Reactive expression for SugNum
  SugNum <- reactive({
    req(input$update)
    if (input$Cruise2 == "WCOA 2021"){
      SugAns <- wcoa_intercept() + (wcoa_slope() * log(input$Depth))
    } else if (input$Cruise2 == "GOMECC 2021"){
      SugAns <- (wcoa_intercept() + gomecc_intercept()) + ((wcoa_slope() + gomecc_slope()) * log(input$Depth))
    } else if (input$Cruise2 == "ECOA 2022"){
      SugAns <- (wcoa_intercept() + ecoa_intercept()) + ((wcoa_slope() + ecoa_slope()) * log(input$Depth))
    }
    as.character(round(SugAns, 0))
  })

output$SugNum <- renderText({
  SugNum()
})

}

```

```{r}
#outputs a Shiny App
shinyApp(ui, server)
```

